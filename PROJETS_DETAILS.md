# Modèle de Détails du Projet

Veuillez remplir ce fichier pour chacun de vos 10 projets. Une fois terminé et enregistré, je pourrai mettre à jour votre portfolio automatiquement.

---

## Projet 1 : Création et requêtage d'une base de données immobilière
- **Catégorie** : Base de données relationnelle
- **Outils** : UML, SQL, IBM Db2, Excel
- **Données** :  Données immobilières publiques (DVF)
- **Lien Présentation (PDF)** : public\docs\projet-1\BD_Immobiliere.pdf
- **Description** : Création d'une base de données relationnelle pour stocker des informations immobilières, puis réalisation de requêtes SQL pour extraire des insights
- **Compétences** : 
    - Charger des données dans une base de données
    - Créer des tables dans une base de données
    - Créer le schéma d'une base de données
    - Effectuer des requêtes SQL pour répondre à une question métier
    - Mettre à jour un catalogue de données


---
## Projet 2 : Analyses d'indicateurs RH
- **Catégorie** : Data Cleaning, Analyse exploratoire, Visualisation
- **Outils** : ETL Knime, Python
- **Données** : Données RH internes fictives
- **Lien Présentation (PDF)** : public\docs\projet-2\Soutenance_P7.pdf
- **Description** : Analyse des indicateurs RH pour améliorer la gestion des ressources humaines
- **Compétences** : 
- Collecter des données en respectant le RGPD
- Préparer des données pour l'analyse en respectant les normes internes à l’entreprise
- Transférer des données vers une zone de préparation


---
## Projet 3 : Analyse des ventes d'une librairie
- **Catégorie** : Analyse exploratoire, Tests statistiques, Visualisation
- **Outils** : Python, Pandas, Scikit-Learn, Scipy, Plotly 
- **Données** : Données de ventes d'une entreprise fictive
- **Lien Présentation (PDF)** : public\docs\projet-3\Analyse_de_ventes.pdf
- **Description** : Analyser les ventes d'une librairie : chiffre d'affaires, produits performants/faibles, profils clients, comportements d'achat.
- **Compétences** : 
- Analyser des séries temporelles
- Réaliser une analyse bivariée pour interpréter des données
- Réaliser un test statistique


---
## Projet 4 : Etude de santé publique
- **Catégorie** : Data Cleaning, Analyse exploratoire, Visualisation
- **Outils** : Python, Pandas, Plotly
-**Données** : FAO (https://www.fao.org/faostat/en/#data) 
- **Lien Présentation (PDF)** : public\docs\projet-4\P4_Piekarec_Soutenance_sans_annexe.pdf
- **Description** : Établissement d’un panorama de l’état de la malnutrition dans le monde pour l’année 2017, en répondant à diverses questions.
- **Compétences** : 
- Créer un environnement de développement
Manipuler des DataFrames
Utiliser des librairies spécialisées pour les traitements data


---
## Projet 5 : Anticipation de besoins en consommation énergétique
- **Catégorie** : Feature Engineering, Apprentissage supervisé, Optimisation de modèle, Explicabilité du modèle 
- **Outils** : Python, Pandas, Scikit-Learn, Plotly
- **Données** : Seattle Data Portal (https://data.seattle.gov/dataset/2016-Building-Energy-Benchmarking/2bpz-gwpy)
- **Lien Présentation (PDF)** : public\docs\projet-5\Piekarec_Sophie_2_Presentation_062022.pdf
- **Description** : Prédiction des émissions de CO₂ et de la consommation totale d’énergie annuelle des bâtiments non résidentiels de Seattle, en se basant sur les données structurelles et les mesures préliminaires.
- **Compétences** : 
- Adapter les hyperparamètres d'un algorithme d'apprentissage supervisé afin de l'améliorer
- Évaluer les performances d’un modèle d'apprentissage supervisé
- Mettre en place le modèle d'apprentissage supervisé adapté au problème métier
- Transformer les variables pertinentes d'un modèle d'apprentissage supervisé


---

## Projet 6 : Segmentation des clients d'un site e-commerce
- **Catégorie** : Analyse exploratoire, Feature engineering, Clustering
- **Outils** : Python, Pandas, Plotly, Scikit-Learn
- **Données** : OLIST (https://www.kaggle.com/olistbr/brazilian-ecommerce)
- **Lien Présentation (PDF)** : public\docs\projet-6\Segmentation_e_commerce.pdf
- **Description** : Segmentation des clients d'un site e-commerce à partir de leurs comportements d'achat, en utilisant des techniques de clustering
- **Compétences** : 
- Adapter les hyperparamètres d'un algorithme non supervisé afin de l'améliorer
- Évaluer les performances d’un modèle d'apprentissage non supervisé
- Transformer les variables pertinentes d'un modèle d'apprentissage non supervisé


---

## Projet 7 : Analyse de données de systèmes éducatifs
- **Catégorie** : Analyse exploratoire, Visualisation
- **Outils** : Python, Pandas, Plotly
- **Données** : Banque mondiale (https://datacatalog.worldbank.org/dataset/education-statistics)
- **Lien Présentation (PDF)** : public\docs\projet-7\Analyse_de_données_de_systèmes_éducatifs.pdf
- **Description** : Analyse des performances des systèmes éducatifs à travers le monde.
- **Compétences** : 
- Effectuer une représentation graphique à l'aide d'une librairie Python adaptée
- Maîtriser les opérations fondamentales du langage Python pour la Data Science
- Manipuler des données avec des librairies Python spécialisées
- Utiliser un notebook Jupyter pour faciliter la rédaction du code et la collaboration
- Mettre en place un environnement Python

--- 

## Projet 8 : Accès à l'eau potable dans le monde
- **Catégorie** : Data Cleaning, Visualisation
- **Outils** : Python, Tableau
- **Données** : FAO et OMS
- **Lien Tableau** : https://public.tableau.com/app/profile/sophie.piekarec/viz/OC_P8DrinkingWaterForAll/DrinkingWaterForAll
- **Description** : Analyse de l'accès à l'eau potable dans différents pays
- **Compétences** : 
- Analyser un besoin client pour formuler des questions analytiques
- Créer un tableau de bord répondant à des questions analytiques
- Générer des graphiques adaptés aux types de données
- Synthétiser des résultats à destination d'un client


--- 

## Projet 9 : Scoring bancaire
- **Catégorie** : Data Cleaning, Analyse exploratoire, Feature Engineering, Apprentissage supervisé, Explicabilité du modèle
- **Outils** :  Python, Pandas, Scikit-Learn, XGBoost, LightGBM, Streamlit, FastAPI, Plotly
- **Données** : Home Credit : https://www.kaggle.com/c/home-credit-default-risk/data
- **Lien Présentation (PDF)** : public\docs\projet-9\Implémentation_d_un_modele_de_scoring.pdf
- **Note méthodologique (PDF)** : public\docs\projet-9\Piekarec_Sophie_3_note_méthodologique_112022.pdf
- **Déploiement (PDF)** : public\\docs\\projet-9\\Piekarec_Sophie_3_dashboard_112022.pdf
- **Lien GitHub** :https://github.com/herospiki/OC
- **Description** : Développement d'un modèle de scoring bancaire pour évaluer la solvabilité des clients.
- **Compétences** : 
- Déployer un modèle via une API dans le Web
- Réaliser un dashboard pour présenter son travail de modélisation
- Rédiger une note méthodologique afin de communiquer sa démarche de modélisation
- Utiliser un logiciel de version de code pour assurer l’intégration du modèle
- Présenter son travail de modélisation à l'oral
- Définir et mettre en œuvre une stratégie de suivi de la performance d’un modèle
- Définir et mettre en œuvre un pipeline d’entraînement des modèles
- Définir la stratégie d’élaboration d’un modèle d’apprentissage supervisé
- Évaluer les performances des modèles d’apprentissage supervisé


--- 

## Projet 10 : Classification automatique de biens de consommation
- **Catégorie** : Data Cleaning, Analyse exploratoire, Feature Engineering, Apprentissage supervisé, NLP, Deep Learning
- **Outils** : Python, Pandas, Scikit-Learn, TensorFlow, Keras, OpenCV, NLTK, spaCy,Plotly
- **Lien Présentation (PDF)** : public\docs\projet-10\Piekarec_Sophie_6_presentation_0922022.pdf
- **Description** : Réalisation d’une première étude de faisabilité d'un moteur de classification d'articles, basé sur une image et une description
- **Compétences** : 
- Prétraiter des données texte pour obtenir un jeu de données exploitable
- Représenter graphiquement des données à grandes dimensions
- Prétraiter des données image pour obtenir un jeu de données exploitable
- Mettre en œuvre des techniques de réduction de dimension
- Utiliser des techniques d’augmentation des données
- Définir la stratégie de collecte de données en recensant les API disponibles
- Définir la stratégie d’élaboration d’un modèle d'apprentissage profond
- Évaluer la performance des modèles d’apprentissage profond selon différents critères




